{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCagg Calculation Example for HNTS-MRG 2024\n",
    "\n",
    "This notebook demonstrates how to calculate the evaluation metric (aggregated Dice Similarity coefficient - DSCagg) for [HNTS-MRG 2024 Challenge](https://hntsmrg24.grand-challenge.org/). More information on the evaluation can be found [here](https://hntsmrg24.grand-challenge.org/tasks-and-evaluation/). The evaluation functions are encapsulated in a Docker container image which will be run on the outputs of participants' submitted algorithms. \n",
    "\n",
    "This specific example in this notebook uses a subset of masks from the HNTS-MRG 2024 training dataset, available on [Zenodo](https://zenodo.org/records/11199559). We use 20 out of 150 training case masks for this example (just as a proof of concept).\n",
    "\n",
    "Credit to the HECKTOR 2022 organizers; most of this code is directly based on their [GitHub implementations](https://github.com/voreille/hecktor/blob/master/notebooks/evaluate_segmentation2022.ipynb).\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Imports](#Imports)\n",
    "2. [Functions](#Functions)\n",
    "3. [DSCagg Calculation](#dscagg-calculation)\n",
    "4. [Extra: Conventional DSC Calculation](#extra-conventional-dsc-calculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_volumes(im):\n",
    "    \"\"\"\n",
    "    Compute the volumes of the GTVp and the GTVn\n",
    "    \"\"\"\n",
    "    spacing = im.GetSpacing()\n",
    "    voxvol = spacing[0] * spacing[1] * spacing[2]\n",
    "    stats = sitk.LabelStatisticsImageFilter()\n",
    "    stats.Execute(im, im)\n",
    "    nvoxels1 = stats.GetCount(1)\n",
    "    nvoxels2 = stats.GetCount(2)\n",
    "    return nvoxels1 * voxvol, nvoxels2 * voxvol\n",
    "\n",
    "def compute_agg_dice(intermediate_results):\n",
    "    \"\"\"\n",
    "    Compute the aggregate dice score from the intermediate results\n",
    "    \"\"\"\n",
    "    aggregate_results = {}\n",
    "    TP1s = [v[\"TP1\"] for v in intermediate_results]\n",
    "    TP2s = [v[\"TP2\"] for v in intermediate_results]\n",
    "    vol_sum1s = [v[\"vol_sum1\"] for v in intermediate_results]\n",
    "    vol_sum2s = [v[\"vol_sum2\"] for v in intermediate_results]\n",
    "    DSCagg1 = 2 * np.sum(TP1s) / np.sum(vol_sum1s)\n",
    "    DSCagg2 = 2 * np.sum(TP2s) / np.sum(vol_sum2s)\n",
    "    aggregate_results['AggregatedDsc'] = {\n",
    "        'GTVp': DSCagg1,\n",
    "        'GTVn': DSCagg2,\n",
    "        'mean': np.mean((DSCagg1, DSCagg2)),\n",
    "    }\n",
    "    return aggregate_results\n",
    "\n",
    "def get_intermediate_metrics(patient_ID, groundtruth, prediction):\n",
    "    \"\"\"\n",
    "    Compute intermediate metrics for a given groundtruth and prediction.\n",
    "    These metrics are used to compute the aggregate dice.\n",
    "    \"\"\"\n",
    "    overlap_measures = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures.SetNumberOfThreads(1)\n",
    "    overlap_measures.Execute(groundtruth, prediction)\n",
    "\n",
    "    DSC1 = overlap_measures.GetDiceCoefficient(1)\n",
    "    DSC2 = overlap_measures.GetDiceCoefficient(2)\n",
    "\n",
    "    vol_gt1, vol_gt2 = compute_volumes(groundtruth)\n",
    "    vol_pred1, vol_pred2 = compute_volumes(prediction)\n",
    "\n",
    "    vol_sum1 = vol_gt1 + vol_pred1\n",
    "    vol_sum2 = vol_gt2 + vol_pred2\n",
    "    TP1 = DSC1 * (vol_sum1) / 2\n",
    "    TP2 = DSC2 * (vol_sum2) / 2\n",
    "    return {\n",
    "        \"PatientID\": patient_ID, # added patient ID so we can pinpoint exact results if needed\n",
    "        \"TP1\": TP1,\n",
    "        \"TP2\": TP2,\n",
    "        \"vol_sum1\": vol_sum1,\n",
    "        \"vol_sum2\": vol_sum2,\n",
    "        \"DSC1\": DSC1,\n",
    "        \"DSC2\": DSC2,\n",
    "        \"vol_gt1\": vol_gt1, # needed if you want to exclude empty ground truths in conventional DSC calcs\n",
    "        \"vol_gt2\": vol_gt2, \n",
    "    }\n",
    "\n",
    "def check_prediction(groundtruth, prediction):\n",
    "    \"\"\"\n",
    "    Check if the prediction is valid and apply padding if needed\n",
    "    \"\"\"\n",
    "\n",
    "    # Cast to the same type\n",
    "    caster = sitk.CastImageFilter()\n",
    "    caster.SetOutputPixelType(sitk.sitkUInt8)\n",
    "    caster.SetNumberOfThreads(1)\n",
    "    groundtruth = caster.Execute(groundtruth)\n",
    "    prediction = caster.Execute(prediction)\n",
    "\n",
    "    # Check labels\n",
    "    stats = sitk.LabelStatisticsImageFilter()\n",
    "    stats.Execute(prediction, prediction)\n",
    "    labels = stats.GetLabels()\n",
    "    if not all([l in [0, 1, 2] for l in labels]):\n",
    "        raise RuntimeError(\n",
    "            \"The labels are incorrect. The labels should be background: 0, GTVp: 1, GTVn: 2.\"\n",
    "        )\n",
    "    # Check spacings\n",
    "    if not np.allclose(\n",
    "            groundtruth.GetSpacing(), prediction.GetSpacing(), atol=0.000001):\n",
    "        raise RuntimeError(\n",
    "            \"The resolution of the prediction is different from the MRI ground truth resolution.\"\n",
    "        )\n",
    "    else:\n",
    "        print('prediction checked, no errors found')\n",
    "        # to be sure that sitk won't trigger unnecessary errors\n",
    "        prediction.SetSpacing(groundtruth.GetSpacing())\n",
    "\n",
    "    # the resample_prediction is used to crop the prediction to the same size as the groundtruth\n",
    "    #return resample_prediction(groundtruth, prediction) # dont wan't this returned for now so commenting out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSCagg Calculation\n",
    "\n",
    "Remember DSCagg is calculated over the entire set of data so you do not get patient-level datapoints like with conventional volumetric DSC.\n",
    "\n",
    "Ground truth masks here are the mid-RT masks while the \"prediction\" masks here are the registered pre-RT masks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction files ['prediction_masks/81_preRT_mask_registered.nii.gz', 'prediction_masks/94_preRT_mask_registered.nii.gz', 'prediction_masks/99_preRT_mask_registered.nii.gz', 'prediction_masks/84_preRT_mask_registered.nii.gz', 'prediction_masks/91_preRT_mask_registered.nii.gz', 'prediction_masks/77_preRT_mask_registered.nii.gz', 'prediction_masks/78_preRT_mask_registered.nii.gz', 'prediction_masks/88_preRT_mask_registered.nii.gz', 'prediction_masks/86_preRT_mask_registered.nii.gz', 'prediction_masks/93_preRT_mask_registered.nii.gz', 'prediction_masks/90_preRT_mask_registered.nii.gz', 'prediction_masks/96_preRT_mask_registered.nii.gz', 'prediction_masks/8_preRT_mask_registered.nii.gz', 'prediction_masks/95_preRT_mask_registered.nii.gz', 'prediction_masks/80_preRT_mask_registered.nii.gz'] \n",
      "\n",
      "Ground truth files ['groundtruth_masks/91_midRT_mask.nii.gz', 'groundtruth_masks/88_midRT_mask.nii.gz', 'groundtruth_masks/94_midRT_mask.nii.gz', 'groundtruth_masks/90_midRT_mask.nii.gz', 'groundtruth_masks/95_midRT_mask.nii.gz', 'groundtruth_masks/77_midRT_mask.nii.gz', 'groundtruth_masks/93_midRT_mask.nii.gz', 'groundtruth_masks/8_midRT_mask.nii.gz', 'groundtruth_masks/96_midRT_mask.nii.gz', 'groundtruth_masks/86_midRT_mask.nii.gz', 'groundtruth_masks/80_midRT_mask.nii.gz', 'groundtruth_masks/78_midRT_mask.nii.gz', 'groundtruth_masks/99_midRT_mask.nii.gz', 'groundtruth_masks/81_midRT_mask.nii.gz', 'groundtruth_masks/84_midRT_mask.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# first set up the ground truth and prediction paths\n",
    "\n",
    "prediction_folder = 'prediction_masks'\n",
    "groundtruth_folder = 'groundtruth_masks'\n",
    "\n",
    "prediction_files = [os.path.join(prediction_folder, file) for file in os.listdir(prediction_folder) if \"nii.gz\" in file]\n",
    "groundtruth_files = [os.path.join(groundtruth_folder, file) for file in os.listdir(groundtruth_folder) if \"nii.gz\" in file]\n",
    "\n",
    "print(\"Prediction files\", prediction_files, \"\\n\")\n",
    "\n",
    "print(\"Ground truth files\", groundtruth_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note in the below code some warnings (LabelOverlapMeasuresImageFilter) are thrown because there is no label in the ground truth file and the prediction file. This is not an error and expected behavior for the given setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating patient 81\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 94\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 99\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 84\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 91\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 77\n",
      "prediction checked, no errors found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /Users/runner/work/1/sitk-build/ITK-prefix/include/ITK-5.3/itkLabelOverlapMeasuresImageFilter.hxx, line 233\n",
      "LabelOverlapMeasuresImageFilter (0x7f817cd98f40): Label \u0002 not found.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating patient 78\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 88\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 86\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 93\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 90\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 96\n",
      "prediction checked, no errors found\n",
      "Evaluating patient 8\n",
      "prediction checked, no errors found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /Users/runner/work/1/sitk-build/ITK-prefix/include/ITK-5.3/itkLabelOverlapMeasuresImageFilter.hxx, line 233\n",
      "LabelOverlapMeasuresImageFilter (0x7f817cd814e0): Label \u0001 not found.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating patient 95\n",
      "prediction checked, no errors found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /Users/runner/work/1/sitk-build/ITK-prefix/include/ITK-5.3/itkLabelOverlapMeasuresImageFilter.hxx, line 233\n",
      "LabelOverlapMeasuresImageFilter (0x7f816c40dc60): Label \u0001 not found.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating patient 80\n",
      "prediction checked, no errors found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /Users/runner/work/1/sitk-build/ITK-prefix/include/ITK-5.3/itkLabelOverlapMeasuresImageFilter.hxx, line 233\n",
      "LabelOverlapMeasuresImageFilter (0x7f817c908fd0): Label \u0002 not found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = list()\n",
    "for f in prediction_files:\n",
    "    patient_ID = os.path.split(f)[-1].split('_')[0] # get the patient ID from the path \n",
    "    gt_file = [k for k in groundtruth_files if os.path.split(k)[-1].split('_')[0] == patient_ID][0]\n",
    "\n",
    "    print(f\"Evaluating patient {patient_ID}\")\n",
    "\n",
    "    prediction = sitk.ReadImage(str(f))\n",
    "    groundtruth = sitk.ReadImage(str(gt_file))\n",
    "    check_prediction(groundtruth, prediction) \n",
    "\n",
    "\n",
    "    results.append(get_intermediate_metrics(patient_ID, groundtruth, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display aggregated DSC metrics. This is what will be used in the challenge evaluation/ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw results are: [{'PatientID': '81', 'TP1': 391.07343593704957, 'TP2': 4460.099424139208, 'vol_sum1': 24023.082493275902, 'vol_sum2': 14405.702132716853, 'DSC1': 0.03255813953488372, 'DSC2': 0.6192130564757211, 'vol_gt1': 838.014505579392, 'vol_gt2': 4838.369860685461}, {'PatientID': '94', 'TP1': 0.0, 'TP2': 2500.0, 'vol_sum1': 3693.5, 'vol_sum2': 9828.0, 'DSC1': 0.0, 'DSC2': 0.5087505087505088, 'vol_gt1': 0.0, 'vol_gt2': 4620.5}, {'PatientID': '99', 'TP1': 1696.4999999999998, 'TP2': 44592.0, 'vol_sum1': 33991.0, 'vol_sum2': 116139.0, 'DSC1': 0.09982054073137006, 'DSC2': 0.7679074212796735, 'vol_gt1': 1696.5, 'vol_gt2': 46632.0}, {'PatientID': '84', 'TP1': 536.5620653779163, 'TP2': 9859.47343994865, 'vol_sum1': 2928.395133385764, 'vol_sum2': 30560.759545830682, 'DSC1': 0.3664546899841018, 'DSC2': 0.6452374604867274, 'vol_gt1': 1094.0744933953172, 'vol_gt2': 11550.633268569285}, {'PatientID': '91', 'TP1': 595.1388605104555, 'TP2': 3307.638731168378, 'vol_sum1': 6276.388589607348, 'vol_sum2': 8108.332946697876, 'DSC1': 0.18964372648816108, 'DSC2': 0.815861596437136, 'vol_gt1': 829.8610715402502, 'vol_gt2': 4130.55535859532}, {'PatientID': '77', 'TP1': 1140.6308548163945, 'TP2': 0.0, 'vol_sum1': 9510.300729290571, 'vol_sum2': 0.0, 'DSC1': 0.2398727205972341, 'DSC2': 0.0, 'vol_gt1': 2779.414776838317, 'vol_gt2': 0.0}, {'PatientID': '78', 'TP1': 1846.9999999999998, 'TP2': 17690.5, 'vol_sum1': 18429.5, 'vol_sum2': 44820.0, 'DSC1': 0.20043951273773025, 'DSC2': 0.7894020526550647, 'vol_gt1': 2213.0, 'vol_gt2': 19238.0}, {'PatientID': '88', 'TP1': 1402.5, 'TP2': 614.0000000000001, 'vol_sum1': 14968.5, 'vol_sum2': 1893.0, 'DSC1': 0.18739352640545145, 'DSC2': 0.6487057580559958, 'vol_gt1': 2604.5, 'vol_gt2': 983.0}, {'PatientID': '86', 'TP1': 0.0, 'TP2': 7694.5, 'vol_sum1': 3692.5, 'vol_sum2': 31439.5, 'DSC1': 0.0, 'DSC2': 0.4894797945259944, 'vol_gt1': 0.0, 'vol_gt2': 11724.0}, {'PatientID': '93', 'TP1': 1933.0, 'TP2': 1081.5, 'vol_sum1': 5667.5, 'vol_sum2': 6228.0, 'DSC1': 0.682134980149978, 'DSC2': 0.3473025048169557, 'vol_gt1': 2004.5, 'vol_gt2': 1663.0}, {'PatientID': '90', 'TP1': 5503.5, 'TP2': 4372.5, 'vol_sum1': 15497.0, 'vol_sum2': 10290.5, 'DSC1': 0.7102665031941666, 'DSC2': 0.8498129342597541, 'vol_gt1': 6723.5, 'vol_gt2': 5086.5}, {'PatientID': '96', 'TP1': 790.5, 'TP2': 234.5, 'vol_sum1': 3937.0, 'vol_sum2': 1065.5, 'DSC1': 0.4015748031496063, 'DSC2': 0.4401689347724073, 'vol_gt1': 1701.5, 'vol_gt2': 501.5}, {'PatientID': '8', 'TP1': 0.0, 'TP2': 11777.0, 'vol_sum1': 0.0, 'vol_sum2': 28656.5, 'DSC1': 0.0, 'DSC2': 0.82194266571284, 'vol_gt1': 0.0, 'vol_gt2': 13020.5}, {'PatientID': '95', 'TP1': 0.0, 'TP2': 17595.52251954273, 'vol_sum1': 0.0, 'vol_sum2': 43566.719506788235, 'DSC1': 0.0, 'DSC2': 0.8077506279443936, 'vol_gt1': 0.0, 'vol_gt2': 19785.633556524677}, {'PatientID': '80', 'TP1': 1621.0000000000002, 'TP2': 0.0, 'vol_sum1': 12447.0, 'vol_sum2': 0.0, 'DSC1': 0.2604643689242388, 'DSC2': 0.0, 'vol_gt1': 1621.0, 'vol_gt2': 0.0}] \n",
      "\n",
      "Aggregate dice scores: {'AggregatedDsc': {'GTVp': 0.2251672584272026, 'GTVn': 0.7249491946997102, 'mean': 0.4750582265634564}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display raw results\n",
    "print(\"The raw results are:\", results, \"\\n\")\n",
    "\n",
    "# Compute and display aggregate dice scores\n",
    "agg_dice_scores = compute_agg_dice(results)\n",
    "print(f\"Aggregate dice scores: {agg_dice_scores}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Conventional DSC Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since conventional volumetric DSC was also calculated during the DSCagg calculation, we can also display these values as well just for reference. These metrics will not be used in the challenge directly but may be handy to know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean DSC1 (GTVp): 0.2247082341264615\n",
      "Mean DSC2 (GTVn): 0.5701023544115448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract DSC1 and DSC2 values\n",
    "DSC1_values = [result[\"DSC1\"] for result in results]\n",
    "DSC2_values = [result[\"DSC2\"] for result in results]\n",
    "\n",
    "# Compute and display mean DSC1 and DSC2\n",
    "mean_DSC1 = np.mean(DSC1_values)\n",
    "mean_DSC2 = np.mean(DSC2_values)\n",
    "print(f\"Mean DSC1 (GTVp): {mean_DSC1}\")\n",
    "print(f\"Mean DSC2 (GTVn): {mean_DSC2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional volumetric DSC may be disproportionately affected by a single false negative/postive result (yielding a DSC of 0). Therefore, it may be more informative to remove instances where the ground truth is empty. The code below removes instances with empty ground truth before computing the mean DSC values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed patient IDs with empty ground truth volumes for DSC1: ['94', '86', '8', '95']\n",
      "Removed patient IDs with empty ground truth volumes for DSC2: ['77', '80'] \n",
      "\n",
      "Mean DSC1 (GTVp) without empty ground truth: 0.30642031926335656\n",
      "Mean DSC2 (GTVn) without empty ground truth: 0.6578104089363979\n"
     ]
    }
   ],
   "source": [
    "# Extract non-zero DSC1 and DSC2 values and print removed patient IDs\n",
    "DSC1_values_nozeros = []\n",
    "DSC2_values_nozeros = []\n",
    "removed_patients_DSC1 = []\n",
    "removed_patients_DSC2 = []\n",
    "\n",
    "for result in results:\n",
    "    patient_id = result[\"PatientID\"]\n",
    "    if result[\"vol_gt1\"] != 0.0:\n",
    "        DSC1_values_nozeros.append(result[\"DSC1\"])\n",
    "    else:\n",
    "        removed_patients_DSC1.append(patient_id)\n",
    "    if result[\"vol_gt2\"] != 0.0:\n",
    "        DSC2_values_nozeros.append(result[\"DSC2\"])\n",
    "    else:\n",
    "        removed_patients_DSC2.append(patient_id)\n",
    "\n",
    "# Print removed patient IDs\n",
    "print(\"Removed patient IDs with empty ground truth volumes for DSC1:\", removed_patients_DSC1)\n",
    "print(\"Removed patient IDs with empty ground truth volumes for DSC2:\", removed_patients_DSC2, \"\\n\")\n",
    "\n",
    "# Compute and display mean non-zero DSC1 and DSC2\n",
    "mean_DSC1_nozeros = np.mean(DSC1_values_nozeros)\n",
    "mean_DSC2_nozeros = np.mean(DSC2_values_nozeros)\n",
    "print(f\"Mean DSC1 (GTVp) without empty ground truth: {mean_DSC1_nozeros}\")\n",
    "print(f\"Mean DSC2 (GTVn) without empty ground truth: {mean_DSC2_nozeros}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
